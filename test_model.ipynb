{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import List, Dict, Any, Tuple, Union, Optional\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from torch_geometric.data import Data\n",
    "from config import get_config\n",
    "\n",
    "from tng_halo.models import GNNBlock\n",
    "from tng_halo import training_utils\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryNodeClassifier(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size: int, \n",
    "        hidden_sizes: List[int], \n",
    "        embed_size: int = None,\n",
    "        graph_layer: str = \"ChebConv\", \n",
    "        graph_layer_args: Dict[str, Any] = None,\n",
    "        activation_name: callable = nn.ReLU(), \n",
    "        layer_norm: bool = False, \n",
    "        norm_first: bool = False,\n",
    "        optimizer_args: Dict[str, Any] = None,\n",
    "        scheduler_args: Dict[str, Any] = None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_sizes = hidden_sizes\n",
    "        self.embed_size = embed_size\n",
    "        self.graph_layer = graph_layer\n",
    "        self.graph_layer_args = graph_layer_args or {}\n",
    "        self.activation_name = activation_name\n",
    "        self.layer_norm = layer_norm\n",
    "        self.norm_first = norm_first\n",
    "        self.optimizer_args = optimizer_args or {}\n",
    "        self.scheduler_args = scheduler_args or {}\n",
    "        self.save_hyperparameters()\n",
    "        self._setup_model()\n",
    "\n",
    "    def _setup_model(self) -> None:\n",
    "        if self.embed_size:\n",
    "            self.embed_layer = nn.Linear(self.input_size, self.embed_size)\n",
    "            input_size = self.embed_size\n",
    "        else:\n",
    "            self.embed_layer = None\n",
    "            input_size = self.input_size\n",
    "\n",
    "        layer_sizes = [input_size] + self.hidden_sizes\n",
    "        activation_fn = training_utils.get_activation(self.activation_name)\n",
    "\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            layer = GNNBlock(\n",
    "                layer_sizes[i-1], \n",
    "                layer_sizes[i], \n",
    "                layer_name=self.graph_layer,\n",
    "                layer_args=self.graph_layer_args, \n",
    "                layer_norm=self.layer_norm, \n",
    "                norm_first=self.norm_first,\n",
    "                activation_fn=activation_fn\n",
    "            )\n",
    "            self.layers.append(layer)\n",
    "        self.output_layer = GNNBlock(\n",
    "            layer_sizes[-1], 1,\n",
    "            layer_name=self.graph_layer,\n",
    "            layer_args=self.graph_layer_args,\n",
    "            layer_norm=self.layer_norm,\n",
    "            norm_first=self.norm_first,\n",
    "            activation_fn=nn.Identity()\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self, \n",
    "        x: torch.Tensor, \n",
    "        edge_index: torch.Tensor,\n",
    "        edge_attr: torch.Tensor = None,\n",
    "        edge_weight: torch.Tensor = None\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        if self.embed_layer:\n",
    "            x = self.embed_layer(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, edge_index, edge_attr, edge_weight)\n",
    "        x = self.output_layer(x, edge_index, edge_attr, edge_weight)\n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        yhat = self.forward(\n",
    "            batch.x, batch.edge_index, batch.edge_attr, batch.edge_weight)\n",
    "        loss = F.binary_cross_entropy_with_logits(yhat, batch.y)\n",
    "        self.log(\n",
    "            \"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation(self, batch, batch_idx):\n",
    "        yhat = self.forward(\n",
    "            batch.x, batch.edge_index, batch.edge_attr, batch.edge_weight)\n",
    "        loss = F.binary_cross_entropy_with_logits(yhat, batch.y)\n",
    "        self.log(\n",
    "            \"val_loss\", loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return training_utils.configure_optimizers(\n",
    "            parameters, self.optimizer_args, self.scheduler_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a random graph\n",
    "x = torch.tensor([[2, 1], [5, 6], [3, 7]], dtype=torch.float)\n",
    "y = torch.tensor([[0], [1], [0]], dtype=torch.float)\n",
    "edge_index = torch.tensor(\n",
    "    [[0, 1, 1, 2], [1, 0, 2, 1]], dtype=torch.long)\n",
    "data = Data(x=x, y=y, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BinaryNodeClassifier(\n",
    "    input_size=config.model.input_size,\n",
    "    hidden_sizes=config.model.hidden_sizes,\n",
    "    embed_size=config.model.embed_size,\n",
    "    graph_layer=config.model.graph_layer,\n",
    "    graph_layer_args=config.model.graph_layer_args,\n",
    "    activation_name=config.model.activation_name,\n",
    "    layer_norm=config.model.layer_norm,\n",
    "    norm_first=config.model.norm_first,\n",
    "    optimizer_args=config.optimizer,\n",
    "    scheduler_args=config.scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.3063],\n",
      "        [-1.1223],\n",
      "        [-0.1839]], grad_fn=<AddBackward0>) tensor(1.1852, grad_fn=<BinaryCrossEntropyWithLogitsBackward0>)\n"
     ]
    }
   ],
   "source": [
    "yhat = model(data.x, data.edge_index)\n",
    "loss = F.binary_cross_entropy_with_logits(yhat, data.y)\n",
    "print(yhat, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geometric",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
